name: Gevals Integration Tests

on:
  pull_request:
    types: [opened, synchronize, reopened, labeled]
  workflow_dispatch:
    inputs:
      task-filter:
        description: 'Regular expression to filter tasks (optional)'
        required: false
        default: ''
      verbose:
        description: 'Enable verbose output'
        required: false
        type: boolean
        default: false

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  GO_VERSION: 1.23
  KIND_CLUSTER_NAME: mcp-eval-cluster

jobs:
  run-evaluation:
    name: Run MCP Evaluation
    runs-on: ubuntu-latest
    env:
      MODEL_KEY: ${{ secrets.MODEL_KEY }}
      MODEL_BASE_URL: ${{ secrets.MODEL_BASE_URL }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Setup Kind cluster
        run: |
          # Install Kind if not present
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind
          
          # Create cluster
          make tools
          make kind-create-cluster KIND_CLUSTER_NAME=${{ env.KIND_CLUSTER_NAME }}

      - name: Deploy Local Environment
        run: |
          # Ensure we use the right cluster name
          export KIND_CLUSTER_NAME=${{ env.KIND_CLUSTER_NAME }}
          
          # Run setup
          make local-env-setup

      - name: Wait for Gateway Readiness
        run: |
          echo "Waiting for MCP Gateway..."
          timeout 300s bash -c 'until curl -s http://localhost:8001/health > /dev/null; do sleep 5; done'
          echo "Gateway is ready!"

      - name: Setup Fallback LLM (Ollama)
        if: env.MODEL_KEY == ''
        uses: ai-action/setup-ollama@v2

      - name: Cache Ollama Models
        if: env.MODEL_KEY == ''
        uses: actions/cache@v4
        with:
          path: ~/.ollama
          key: ${{ runner.os }}-ollama-qwen2.5-1.5b

      - name: Run Agent (Fallback)
        if: env.MODEL_KEY == ''
        run: |
          echo "No MODEL_KEY secret found. Starting Ollama..."
          
          # Start Ollama in background
          ollama serve &
          
          # Wait for Ollama to be ready
          echo "Waiting for Ollama to be ready..."
          timeout 60s bash -c 'until curl -s http://localhost:11434 > /dev/null; do sleep 2; done'
          
          MODEL_NAME="qwen2.5:1.5b"
          
          # Pull the model (Ollama will skip if cached/present)
          echo "Pulling model $MODEL_NAME..."
          ollama pull $MODEL_NAME
          
          # Configure environment for mcpchecker
          echo "MODEL_BASE_URL=http://localhost:11434/v1" >> $GITHUB_ENV
          echo "MODEL_KEY=ollama" >> $GITHUB_ENV
          
          # Update agent.yaml to use the fallback model
          sed -i "s/model: .*/model: \"$MODEL_NAME\"/" evals/gemini-agent/agent.yaml
          
          echo "Ollama setup complete using model $MODEL_NAME"

      - name: Run mcpchecker (Manual)
        run: |
          echo "Installing mcpchecker..."
          go install github.com/mcpchecker/mcpchecker/cmd/mcpchecker@latest
          
          echo "Running mcpchecker..."
          # Ensure GOBIN is in PATH if not already (github actions usually has it)
          export PATH=$PATH:$(go env GOPATH)/bin
          mcpchecker check --verbose evals/gemini-agent/eval.yaml

      - name: Upload Evaluation Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mcpchecker-results
          path: mcpchecker-*-out.json
          retention-days: 5
